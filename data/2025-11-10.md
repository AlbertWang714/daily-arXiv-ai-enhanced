<div id=toc></div>

# Table of Contents

- [cs.CL](#cs.CL) [Total: 37]
- [cs.AI](#cs.AI) [Total: 5]


<div id='cs.CL'></div>

# cs.CL [[Back]](#toc)

### [1] [Evaluating LLMs' Reasoning Over Ordered Procedural Steps](https://arxiv.org/abs/2511.04688)
*Adrita Anika,Md Messal Monem Miah*

Main category: cs.CL

TL;DR: 研究评估了大型语言模型（LLMs）在从乱序步骤重建全局有序序列任务中的表现，使用食谱数据集和多种评估指标，发现模型在长序列和严重乱序输入下表现下降。


<details>
  <summary>Details</summary>
Motivation: 探索LLMs在处理程序性序列任务时的能力，尤其是正确排序对结果至关重要的领域（如食谱），以评估模型在零样本和少样本设置下的表现。

Method: 使用包含食物食谱的数据集，评估多种LLMs在重建乱序步骤任务中的表现，采用了Kendall's Tau、NLCS和NED等排序和序列对齐指标。

Result: 研究发现，模型性能随序列长度增加而下降，输入步骤的更大位移（更严重的乱序）导致性能进一步降低。

Conclusion: 当前LLMs在处理程序性推理任务时存在局限性，尤其是面对较长和更无序的输入。

Abstract: Reasoning over procedural sequences, where the order of steps directly
impacts outcomes, is a critical capability for large language models (LLMs). In
this work, we study the task of reconstructing globally ordered sequences from
shuffled procedural steps, using a curated dataset of food recipes, a domain
where correct sequencing is essential for task success. We evaluate several
LLMs under zero-shot and few-shot settings and present a comprehensive
evaluation framework that adapts established metrics from ranking and sequence
alignment. These include Kendall's Tau, Normalized Longest Common Subsequence
(NLCS), and Normalized Edit Distance (NED), which capture complementary aspects
of ordering quality. Our analysis shows that model performance declines with
increasing sequence length, reflecting the added complexity of longer
procedures. We also find that greater step displacement in the input,
corresponding to more severe shuffling, leads to further degradation. These
findings highlight the limitations of current LLMs in procedural reasoning,
especially with longer and more disordered inputs.

</details>


### [2] [Adaptive Testing for LLM Evaluation: A Psychometric Alternative to Static Benchmarks](https://arxiv.org/abs/2511.04689)
*Peiyu Li,Xiuxiu Tang,Si Chen,Ying Cheng,Ronald Metoyer,Ting Hua,Nitesh V. Chawla*

Main category: cs.CL

TL;DR: 论文提出了一种基于项目反应理论（IRT）的自适应测试框架ATLAS，通过Fisher信息引导的项目选择，显著减少评估所需的项目数量（90%减少），同时保持测量精度。


<details>
  <summary>Details</summary>
Motivation: 现有的语言模型评估方法通常固定使用大量基准项目，忽略了项目质量的差异，导致评估成本高、效率低，且可能存在标注错误。

Method: 采用项目反应理论（IRT）和Fisher信息引导的项目选择，动态调整测试项目以精确估计模型能力。

Result: ATLAS在HellaSwag基准上仅用42个项目（原有5608个）就达到0.154的平均绝对误差，项目暴露率低于10%，测试重叠率为16-27%。IRT排名与传统准确率排名存在显著差异。

Conclusion: ATLAS框架通过自适应测试显著提高了评估效率，同时揭示了传统静态基准的局限性，为语言模型评估提供了更精准的方法。

Abstract: Large language model evaluation requires thousands of benchmark items, making
evaluations expensive and slow. Existing methods compute average accuracy
across fixed item sets, treating all items equally despite varying quality and
informativeness. We present ATLAS an adaptive testing framework using Item
Response Theory (IRT) to estimate model ability through Fisher
information-guided item selection. Our analysis of five major benchmarks
reveals that 3-6% of items exhibit negative discrimination, indicating
annotation errors that corrupt static evaluation. ATLAS achieves 90% item
reduction while maintaining measurement precision: on HellaSwag (5,608 items),
we match full-benchmark estimates using only 42 items with 0.154 MAE. Our
framework maintains item exposure rates below 10% and test overlap at 16-27%,
compared to static benchmarks where every model sees all items (100% exposure).
Among 4,000+ tested models, IRT ranks differ from accuracy ranks: models with
the same accuracy get different IRT scores, and 23-31% of all models shift by
more than 10 rank positions. Code and calibrated item banks are available at
https://github.com/Peiyu-Georgia-Li/ATLAS.git.

</details>


### [3] [SARC: Sentiment-Augmented Deep Role Clustering for Fake News Detection](https://arxiv.org/abs/2511.04692)
*Jingqing Wang,Jiaxing Shang,Rong Xu,Fei Hao,Tianjin Huang,Geyong Min*

Main category: cs.CL

TL;DR: SARC框架通过情感增强的深度聚类区分用户角色，提升假新闻检测性能。


<details>
  <summary>Details</summary>
Motivation: 现有假新闻检测方法忽视用户角色差异对情感特征的潜在影响，限制检测效果。

Method: 结合BiGRU和注意力机制生成用户特征，构建可微分深度聚类模块分类用户角色，联合优化角色聚类与假新闻检测目标。

Result: 在RumourEval-19和Weibo-comp数据集上超越基线模型，性能全面领先。

Conclusion: SARC通过区分用户角色与联合优化策略，显著提升了假新闻检测的准确性。

Abstract: Fake news detection has been a long-standing research focus in social
networks. Recent studies suggest that incorporating sentiment information from
both news content and user comments can enhance detection performance. However,
existing approaches typically treat sentiment features as auxiliary signals,
overlooking role differentiation, that is, the same sentiment polarity may
originate from users with distinct roles, thereby limiting their ability to
capture nuanced patterns for effective detection. To address this issue, we
propose SARC, a Sentiment-Augmented Role Clustering framework which utilizes
sentiment-enhanced deep clustering to identify user roles for improved fake
news detection. The framework first generates user features through joint
comment text representation (with BiGRU and Attention mechanism) and sentiment
encoding. It then constructs a differentiable deep clustering module to
automatically categorize user roles. Finally, unlike existing approaches which
take fake news label as the unique supervision signal, we propose a joint
optimization objective integrating role clustering and fake news detection to
further improve the model performance. Experimental results on two benchmark
datasets, RumourEval-19 and Weibo-comp, demonstrate that SARC achieves superior
performance across all metrics compared to baseline models. The code is
available at: https://github.com/jxshang/SARC.

</details>


### [4] [Reasoning Up the Instruction Ladder for Controllable Language Models](https://arxiv.org/abs/2511.04694)
*Zishuo Zheng,Vidhisha Balachandran,Chan Young Park,Faeze Brahman,Sachin Kumar*

Main category: cs.CL

TL;DR: 该论文探讨了如何通过训练使大语言模型（LLM）具备指令层级（IH）解决能力，以确保其在多源指令冲突时可靠生成响应，并提高模型的安全性和可控性。


<details>
  <summary>Details</summary>
Motivation: 随着大语言模型在现实决策中的作用越来越重要，需要解决来自多源（如开发者、用户、工具）的指令冲突问题，以确保模型的可靠性和可控性。

Method: 将指令层级解决重新定义为推理任务，通过构建数据集VerIH（包含对齐和冲突的系统-用户指令）进行轻量级强化学习训练，使模型具备指令优先级的推理能力。

Result: 经过训练后的模型在指令遵循和指令层级测试中表现显著提升，且在安全关键场景下（如对抗性输入）也表现出更强的鲁棒性。

Conclusion: 通过推理指令层级，为提升大语言模型的可靠性和可控性提供了一条实用路径，使系统提示的更新能够更可控地改变模型行为。

Abstract: As large language model (LLM) based systems take on high-stakes roles in
real-world decision-making, they must reconcile competing instructions from
multiple sources (e.g., model developers, users, and tools) within a single
prompt context. Thus, enforcing an instruction hierarchy (IH) in LLMs, where
higher-level directives override lower-priority requests, is critical for the
reliability and controllability of LLMs. In this work, we reframe instruction
hierarchy resolution as a reasoning task. Specifically, the model must first
"think" about the relationship between a given user prompt and higher-priority
(system) instructions before generating a response. To enable this capability
via training, we construct VerIH, an instruction hierarchy dataset of
constraint-following tasks with verifiable answers. This dataset comprises both
aligned and conflicting system-user instructions. We show that lightweight
reinforcement learning with VerIH effectively transfers general reasoning
capabilities of models to instruction prioritization. Our finetuned models
achieve consistent improvements on instruction following and instruction
hierarchy benchmarks. This reasoning ability also generalizes to
safety-critical settings beyond the training distribution. By treating safety
issues as resolving conflicts between adversarial user inputs and predefined
higher-priority policies, our trained model enhances robustness against
jailbreak and prompt injection attacks. These results demonstrate that
reasoning over instruction hierarchies provides a practical path to reliable
LLMs, where updates to system prompts yield controllable and robust changes in
model behavior.

</details>


### [5] [EncouRAGe: Evaluating RAG Local, Fast, and Reliable](https://arxiv.org/abs/2511.04696)
*Jan Strich,Adeline Scharfenberg,Chris Biemann,Martin Semmann*

Main category: cs.CL

TL;DR: EncouRAGe是一个Python框架，旨在简化和评估基于大型语言模型和嵌入模型的检索增强生成系统。它提供了五个模块化组件，支持灵活开发和评估。


<details>
  <summary>Details</summary>
Motivation: 为了解决检索增强生成系统开发中的复杂性和评估不足的问题，EncouRAGe提供了模块化和可扩展的工具，支持科学可重复性和多样化评估。

Method: 框架包括五种组件：Type Manifest、RAG Factory、Inference、Vector Store和Metrics，支持本地部署和灵活的评估方式。

Result: 实验结果表明，RAG系统性能仍低于Oracle Context，而Hybrid BM25在四个数据集中表现最佳。重新排序仅带来小幅性能提升，但增加了响应延迟。

Conclusion: EncouRAGe为RAG系统的开发和评估提供了高效工具，但RAG本身仍有优化空间，而Hybrid BM25是一个更优的选择。

Abstract: We introduce EncouRAGe, a comprehensive Python framework designed to
streamline the development and evaluation of Retrieval-Augmented Generation
(RAG) systems using Large Language Models (LLMs) and Embedding Models.
EncouRAGe comprises five modular and extensible components: Type Manifest, RAG
Factory, Inference, Vector Store, and Metrics, facilitating flexible
experimentation and extensible development. The framework emphasizes scientific
reproducibility, diverse evaluation metrics, and local deployment, enabling
researchers to efficiently assess datasets within RAG workflows. This paper
presents implementation details and an extensive evaluation across multiple
benchmark datasets, including 25k QA pairs and over 51k documents. Our results
show that RAG still underperforms compared to the Oracle Context, while Hybrid
BM25 consistently achieves the best results across all four datasets. We
further examine the effects of reranking, observing only marginal performance
improvements accompanied by higher response latency.

</details>


### [6] [multiMentalRoBERTa: A Fine-tuned Multiclass Classifier for Mental Health Disorder](https://arxiv.org/abs/2511.04698)
*K M Sajjadul Islam,John Fields,Praveen Madiraju*

Main category: cs.CL

TL;DR: 该论文提出了一种名为multiMentalRoBERTa的微调RoBERTa模型，用于从社交媒体文本中早期检测常见心理健康问题，并在多类分类任务中表现出色。


<details>
  <summary>Details</summary>
Motivation: 早期检测心理健康问题对于及时提供支持和风险评估至关重要，尤其是在社交媒体文本中。

Method: 通过整合多个数据集，分析了类别重叠情况，并比较了传统机器学习方法、领域专用Transformer模型和基于提示的大语言模型。multiMentalRoBERTa在六类和五类分类任务中表现最优。

Result: multiMentalRoBERTa的宏观F1分数在六类任务中为0.839，在五类任务中为0.870，优于其他方法。同时，运用了可解释性方法分析分类驱动因素。

Conclusion: 研究证明了微调Transformer模型在敏感任务中的可靠性和可解释性，并强调了公平性和偏见缓解的重要性。multiMentalRoBERTa是一种轻量级且可部署的解决方案。

Abstract: The early detection of mental health disorders from social media text is
critical for enabling timely support, risk assessment, and referral to
appropriate resources. This work introduces multiMentalRoBERTa, a fine-tuned
RoBERTa model designed for multiclass classification of common mental health
conditions, including stress, anxiety, depression, post-traumatic stress
disorder (PTSD), suicidal ideation, and neutral discourse. Drawing on multiple
curated datasets, data exploration is conducted to analyze class overlaps,
revealing strong correlations between depression and suicidal ideation as well
as anxiety and PTSD, while stress emerges as a broad, overlapping category.
Comparative experiments with traditional machine learning methods,
domain-specific transformers, and prompting-based large language models
demonstrate that multiMentalRoBERTa achieves superior performance, with macro
F1-scores of 0.839 in the six-class setup and 0.870 in the five-class setup
(excluding stress), outperforming both fine-tuned MentalBERT and baseline
classifiers. Beyond predictive accuracy, explainability methods, including
Layer Integrated Gradients and KeyBERT, are applied to identify lexical cues
that drive classification, with a particular focus on distinguishing depression
from suicidal ideation. The findings emphasize the effectiveness of fine-tuned
transformers for reliable and interpretable detection in sensitive contexts,
while also underscoring the importance of fairness, bias mitigation, and
human-in-the-loop safety protocols. Overall, multiMentalRoBERTa is presented as
a lightweight, robust, and deployable solution for enhancing support in mental
health platforms.

</details>


### [7] [Cross-Lingual SynthDocs: A Large-Scale Synthetic Corpus for Any to Arabic OCR and Document Understanding](https://arxiv.org/abs/2511.04699)
*Haneen Al-Homoud,Asma Ibrahim,Murtadha Al-Jubran,Fahad Al-Otaibi,Yazeed Al-Harbi,Daulet Toibazar,Kesen Wang,Pedro J. Moreno*

Main category: cs.CL

TL;DR: Cross-Lingual SynthDocs是一个大规模合成语料库，旨在解决阿拉伯语OCR和文档理解资源稀缺的问题，包含超过250万个样本，且在多个阿拉伯语基准测试中表现出色。


<details>
  <summary>Details</summary>
Motivation: 解决阿拉伯语在OCR和文档理解领域资源稀缺的问题，提供高质量的合成数据以支持研究和应用。

Method: 利用真实扫描背景、双语布局和音标感知字体生成合成数据，涵盖文本、表格和图表等多种文档元素。

Result: 在多个阿拉伯语基准测试中，SynthDocs显著降低了WER和CER，同时提升了TEDS和CharTeX的性能。

Conclusion: SynthDocs是一个可扩展且视觉逼真的资源，能够推动多语言文档分析研究的进展。

Abstract: Cross-Lingual SynthDocs is a large-scale synthetic corpus designed to address
the scarcity of Arabic resources for Optical Character Recognition (OCR) and
Document Understanding (DU). The dataset comprises over 2.5 million of samples,
including 1.5 million textual data, 270K fully annotated tables, and hundred
thousands of real data based charts. Our pipeline leverages authentic scanned
backgrounds, bilingual layouts, and diacritic aware fonts to capture the
typographic and structural complexity of Arabic documents. In addition to text,
the corpus includes variety of rendered styles for charts and tables.
Finetuning Qwen-2.5-VL on SynthDocs yields consistent improvements in Word
Error Rate (WER) and Character Error Rate (CER) in terms of OCR across multiple
public Arabic benchmarks, Tree-Edit Distance Similarity (TEDS) and Chart
Extraction Score (CharTeX) improved as well in other modalities. SynthDocs
provides a scalable, visually realistic resource for advancing research in
multilingual document analysis.

</details>


### [8] [Separate the Wheat from the Chaff: Winnowing Down Divergent Views in Retrieval Augmented Generation](https://arxiv.org/abs/2511.04700)
*Song Wang,Zihan Chen,Peng Wang,Zhepei Wei,Zhen Tan,Yu Meng,Cong Shen,Jundong Li*

Main category: cs.CL

TL;DR: WinnowRAG是一个新颖的RAG框架，通过两阶段方法过滤噪声文档并保留有用内容，提升生成响应的准确性。


<details>
  <summary>Details</summary>
Motivation: 解决传统RAG在增加检索文档数量时引入噪声的问题。

Method: 两阶段框架：第一阶段通过查询感知聚类分组文档并生成答案；第二阶段通过LLM批评家迭代过滤噪声文档并使用战略合并保留有用内容。

Result: WinnowRAG在多个真实数据集上表现优于现有基线方法。

Conclusion: WinnowRAG模型无关且无需微调，具有广泛适用性和高效性。

Abstract: Retrieval-augmented generation (RAG) enhances large language models (LLMs) by
integrating external knowledge sources to address their limitations in
accessing up-to-date or specialized information. A natural strategy to increase
the likelihood of retrieving relevant information is to expand the number of
retrieved documents. However, involving more documents could introduce
significant noise, as many documents may be irrelevant or misleading, thereby
reducing the overall accuracy of the generated responses. To overcome the
challenge associated with handling a larger number of documents, we propose
WinnowRAG, a novel RAG framework designed to systematically filter out noisy
documents while preserving valuable content -- a process we refer to as
winnowing. WinnowRAG operates in two stages: In Stage I, we perform query-aware
clustering to group similar documents and form distinct topic clusters. Each
cluster is assigned to an LLM agent for generating a unique answer. In Stage
II, we perform winnowing, wherein a critic LLM evaluates the outputs of
multiple agents and iteratively separates useful documents from noisy ones. To
retain useful documents when discarding agents, we propose two strategic
merging techniques to ensure that only relevant knowledge is used for
generating the final response. Crucially, WinnowRAG is model-agnostic and does
not require any model fine-tuning, making it easily adaptable to various tasks.
Extensive experiments on various realistic datasets demonstrate the
effectiveness of WinnowRAG over state-of-the-art baselines.

</details>


### [9] [Measuring what Matters: Construct Validity in Large Language Model Benchmarks](https://arxiv.org/abs/2511.04703)
*Andrew M. Bean,Ryan Othniel Kearns,Angelika Romanou,Franziska Sofia Hafner,Harry Mayne,Jan Batzner,Negar Foroutan,Chris Schmitz,Karolina Korgul,Hunar Batra,Oishi Deb,Emma Beharry,Cornelius Emde,Thomas Foster,Anna Gausen,María Grandury,Simeng Han,Valentin Hofmann,Lujain Ibrahim,Hazel Kim,Hannah Rose Kirk,Fangru Lin,Gabrielle Kaili-May Liu,Lennart Luettgau,Jabez Magomere,Jonathan Rystrøm,Anna Sotnikova,Yushi Yang,Yilun Zhao,Adel Bibi,Antoine Bosselut,Ronald Clark,Arman Cohan,Jakob Foerster,Yarin Gal,Scott A. Hale,Inioluwa Deborah Raji,Christopher Summerfield,Philip H. S. Torr,Cozmin Ududec,Luc Rocher,Adam Mahdi*

Main category: cs.CL

TL;DR: 该论文通过系统评估445个大语言模型（LLM）基准测试，揭示了当前评估方法在效度上的不足，并提出了八项改进建议。


<details>
  <summary>Details</summary>
Motivation: 评估大语言模型（LLM）的能力及其安全性和鲁棒性，是确保其有效部署的关键步骤。

Method: 研究团队由29名专家组成，系统审查了自然语言处理和机器学习领域顶级会议中的445个LLM基准测试。

Result: 研究发现当前基准测试在现象衡量、任务设计和评分指标上存在效度不足的问题。

Conclusion: 论文提出了八项具体建议，为开发更有效的LLM基准测试提供了详细指导。

Abstract: Evaluating large language models (LLMs) is crucial for both assessing their
capabilities and identifying safety or robustness issues prior to deployment.
Reliably measuring abstract and complex phenomena such as 'safety' and
'robustness' requires strong construct validity, that is, having measures that
represent what matters to the phenomenon. With a team of 29 expert reviewers,
we conduct a systematic review of 445 LLM benchmarks from leading conferences
in natural language processing and machine learning. Across the reviewed
articles, we find patterns related to the measured phenomena, tasks, and
scoring metrics which undermine the validity of the resulting claims. To
address these shortcomings, we provide eight key recommendations and detailed
actionable guidance to researchers and practitioners in developing LLM
benchmarks.

</details>


### [10] [GEMMA-SQL: A Novel Text-to-SQL Model Based on Large Language Models](https://arxiv.org/abs/2511.04710)
*Hari Mohan Pandey,Anshul Gupta,Subham Sarkar,Minakshi Tomer,Schneider Johannes,Yan Gong*

Main category: cs.CL

TL;DR: GEMMA-SQL是一种基于Gemma 2B架构的轻量级、高效文本到SQL模型，通过资源高效的微调和多种提示策略提升SQL生成准确性，在SPIDER基准测试中表现优于现有基线模型。


<details>
  <summary>Details</summary>
Motivation: 旨在提供一个无需专业编程知识即可通过自然语言与结构化数据库交互的解决方案，同时探索高效、低成本的文本到SQL模型设计。

Method: 基于Gemma 2B架构，通过资源高效的迭代微调和多种提示策略（包括少样本学习）优化SQL生成。

Result: GEMMA-SQL Instruct在Test-Suite和Exact Set Match上的准确率分别为66.8%和63.3%，优于IRNet、RYANSQL和CodeXDavinci等基线模型。

Conclusion: GEMMA-SQL表明有效的提示设计和针对性指令微调能在保持高扩展性和适应性的同时显著提升性能，使其成为实用且开源的文本到SQL系统选择。

Abstract: Text-to-SQL systems enable users to interact with structured databases using
natural language, eliminating the need for specialized programming knowledge.
In this work, we introduce GEMMA-SQL, a lightweight and efficient text-to-SQL
model built upon the open-source Gemma 2B architecture. Unlike many large
language models (LLMs), GEMMA-SQL is fine-tuned in a resource-efficient,
iterative manner and can be deployed on low-cost hardware. Leveraging the
SPIDER benchmark for training and evaluation, GEMMA-SQL combines multiple
prompting strategies, including few-shot learning, to enhance SQL query
generation accuracy. The instruction-tuned variant, GEMMA-SQL Instruct,
achieves 66.8% Test-Suite accuracy and 63.3% Exact Set Match accuracy,
outperforming several state-of-the-art baselines such as IRNet, RYANSQL, and
CodeXDavinci. The proposed approach demonstrates that effective prompt design
and targeted instruction tuning can significantly boost performance while
maintaining high scalability and adaptability. These results position GEMMA-SQL
as a practical, open-source alternative for robust and accessible text-to-SQL
systems.

</details>


### [11] [First is Not Really Better Than Last: Evaluating Layer Choice and Aggregation Strategies in Language Model Data Influence Estimation](https://arxiv.org/abs/2511.04715)
*Dmytro Vitel,Anshuman Chhabra*

Main category: cs.CL

TL;DR: 研究发现，大型语言模型（LLM）决策的样本影响分析中，中间注意力层比嵌入层更适合估计影响，并提出新的评估方法和指标NDR。


<details>
  <summary>Details</summary>
Motivation: 为了更准确地解释LLM的决策并审计数据集，需要改进现有样本影响估计方法的局限性和不可靠性。

Method: 通过理论和实验证据验证中间注意力层的效果，并采用排名和投票等方法替代标准平均，引入NDR指标。

Result: 实验表明，嵌入层并非估算样本影响的最佳选择，中间层表现更好，NDR指标优于传统方法。

Conclusion: 研究成果挑战了领域内的传统认知，为LLM样本影响分析提供了更可靠的方法和指标。

Abstract: Identifying how training samples influence/impact Large Language Model (LLM)
decision-making is essential for effectively interpreting model decisions and
auditing large-scale datasets. Current training sample influence estimation
methods (also known as influence functions) undertake this goal by utilizing
information flow through the model via its first-order and higher-order
gradient terms. However, owing to the large model sizes of today consisting of
billions of parameters, these influence computations are often restricted to
some subset of model layers to ensure computational feasibility. Prior seminal
work by Yeh et al. (2022) in assessing which layers are best suited for
computing language data influence concluded that the first (embedding) layers
are the most informative for this purpose, using a hypothesis based on
influence scores canceling out (i.e., the cancellation effect). In this work,
we propose theoretical and empirical evidence demonstrating how the
cancellation effect is unreliable, and that middle attention layers are better
estimators for influence. Furthermore, we address the broader challenge of
aggregating influence scores across layers, and showcase how alternatives to
standard averaging (such as ranking and vote-based methods) can lead to
significantly improved performance. Finally, we propose better methods for
evaluating influence score efficacy in LLMs without undertaking model
retraining, and propose a new metric known as the Noise Detection Rate (NDR)
that exhibits strong predictive capability compared to the cancellation effect.
Through extensive experiments across LLMs of varying types and scales, we
concretely determine that the first (layers) are not necessarily better than
the last (layers) for LLM influence estimation, contrasting with prior
knowledge in the field.

</details>


### [12] [Surprisal reveals diversity gaps in image captioning and different scorers change the story](https://arxiv.org/abs/2511.04754)
*Nikolai Ilinykh,Simon Dobnik*

Main category: cs.CL

TL;DR: 该论文提出了一种基于信息熵的语言多样性度量方法（surprisal variance），用于评估图像描述任务的多样性。通过比较五种先进视觉语言模型和人类描述的多样性，发现多样性结论依赖于评分模型的选择。


<details>
  <summary>Details</summary>
Motivation: 量化图像描述任务中的语言多样性，并揭示依赖单一评分模型可能导致多样性结论反转的问题。

Method: 使用信息熵方差（surprisal variance）作为多样性度量，对比五种视觉语言模型和人类描述在MSCOCO测试集上的表现，分别用图像描述训练的语言模型和通用语言模型评分。

Result: 人类描述的多样性在图像描述训练的语言模型下是模型的两倍，但在通用语言模型下反转。多样性结论依赖于评分模型的选择。

Conclusion: 提出了基于信息熵的多样性度量方法，并强调多样性评估需在多种评分模型下进行以确保结论的稳健性。

Abstract: We quantify linguistic diversity in image captioning with surprisal variance
- the spread of token-level negative log-probabilities within a caption set. On
the MSCOCO test set, we compare five state-of-the-art vision-and-language LLMs,
decoded with greedy and nucleus sampling, to human captions. Measured with a
caption-trained n-gram LM, humans display roughly twice the surprisal variance
of models, but rescoring the same captions with a general-language model
reverses the pattern. Our analysis introduces the surprisal-based diversity
metric for image captioning. We show that relying on a single scorer can
completely invert conclusions, thus, robust diversity evaluation must report
surprisal under several scorers.

</details>


### [13] [Explore Data Left Behind in Reinforcement Learning for Reasoning Language Models](https://arxiv.org/abs/2511.04800)
*Chenxi Liu,Junjie Liang,Yuqi Jia,Bochuan Cao,Yang Bai,Heng Huang,Xun Chen*

Main category: cs.CL

TL;DR: RLVR用于提升大语言模型的推理能力，但训练中零方差奖励的残差提示导致训练信号丢失。ERPO通过鼓励探索残差提示并激活其训练信号，提升模型性能。


<details>
  <summary>Details</summary>
Motivation: 随着模型训练时间增长和规模扩大，残差提示（零方差奖励的提示）增多，导致训练信号减少，降低了多样性和效果。需要充分利用这些残差提示。

Method: 提出ERPO框架，通过历史跟踪和自适应增加采样温度，鼓励模型在残差提示上生成更多样化的推理轨迹，从而激活训练信号。

Result: 在Qwen2.5系列上，ERPO在多个数学推理基准测试中均超越了强基线。

Conclusion: ERPO能有效利用残差提示，提升模型训练的多样性和效果。

Abstract: Reinforcement Learning with Verifiable Rewards (RLVR) has emerged as an
effective approach for improving the reasoning abilities of large language
models (LLMs). The Group Relative Policy Optimization (GRPO) family has
demonstrated strong performance in training LLMs with RLVR. However, as models
train longer and scale larger, more training prompts become residual prompts,
those with zero variance rewards that provide no training signal. Consequently,
fewer prompts contribute to training, reducing diversity and hindering
effectiveness. To fully exploit these residual prompts, we propose the Explore
Residual Prompts in Policy Optimization (ERPO) framework, which encourages
exploration on residual prompts and reactivates their training signals. ERPO
maintains a history tracker for each prompt and adaptively increases the
sampling temperature for residual prompts that previously produced all correct
responses. This encourages the model to generate more diverse reasoning traces,
introducing incorrect responses that revive training signals. Empirical results
on the Qwen2.5 series demonstrate that ERPO consistently surpasses strong
baselines across multiple mathematical reasoning benchmarks.

</details>


### [14] [Trained on Tokens, Calibrated on Concepts: The Emergence of Semantic Calibration in LLMs](https://arxiv.org/abs/2511.04869)
*Preetum Nakkiran,Arwen Bradley,Adam Goliński,Eugene Ndiaye,Michael Kirchhof,Sinead Williamson*

Main category: cs.CL

TL;DR: 研究发现，基础大语言模型（LLMs）在开放域问答任务中表现出良好的语义校准能力，尽管未被明确训练来评估其输出的置信度。


<details>
  <summary>Details</summary>
Motivation: 探讨大语言模型是否能够超越词元级别，评估其输出内容的语义置信度。

Method: 基于采样的语义校准方法，结合理论与实验验证，提出B校准机制，并通过实验验证其预测。

Result: 基础LLMs在问答任务中表现出语义校准能力，但强化学习指令微调和思维链推理会破坏这种校准。

Conclusion: 研究首次从理论角度解释了LLMs中语义校准的出现条件和原因。

Abstract: Large Language Models (LLMs) often lack meaningful confidence estimates for
their outputs. While base LLMs are known to exhibit next-token calibration, it
remains unclear whether they can assess confidence in the actual meaning of
their responses beyond the token level. We find that, when using a certain
sampling-based notion of semantic calibration, base LLMs are remarkably
well-calibrated: they can meaningfully assess confidence in open-domain
question-answering tasks, despite not being explicitly trained to do so. Our
main theoretical contribution establishes a mechanism for why semantic
calibration emerges as a byproduct of next-token prediction, leveraging a
recent connection between calibration and local loss optimality. The theory
relies on a general definition of "B-calibration," which is a notion of
calibration parameterized by a choice of equivalence classes (semantic or
otherwise). This theoretical mechanism leads to a testable prediction: base
LLMs will be semantically calibrated when they can easily predict their own
distribution over semantic answer classes before generating a response. We
state three implications of this prediction, which we validate through
experiments: (1) Base LLMs are semantically calibrated across
question-answering tasks, (2) RL instruction-tuning systematically breaks this
calibration, and (3) chain-of-thought reasoning breaks calibration. To our
knowledge, our work provides the first principled explanation of when and why
semantic calibration emerges in LLMs.

</details>


### [15] [Minimal and Mechanistic Conditions for Behavioral Self-Awareness in LLMs](https://arxiv.org/abs/2511.04875)
*Matthew Bozoukov,Matthew Nguyen,Shubkarman Singh,Bart Bussmann,Patrick Leask*

Main category: cs.CL

TL;DR: LLMs可以通过低秩适配器（LoRA）诱导行为自我意识，表现为特定领域的线性特征。


<details>
  <summary>Details</summary>
Motivation: 研究LLMs行为自我意识的出现条件和机制，以应对潜在的安全问题，如模型在评估中隐藏真实能力。

Method: 通过在指令调优的LLMs上使用低秩适配器（LoRA）进行控制实验。

Result: 发现：（1）使用单秩-1 LoRA适配器可可靠诱导自我意识；（2）自我意识行为可由激活空间中的单一导向向量捕获；（3）自我意识是领域局部化的。

Conclusion: 行为自我意识是领域特异性的线性特征，可被轻易诱导和调节。

Abstract: Recent studies have revealed that LLMs can exhibit behavioral self-awareness:
the ability to accurately describe or predict their own learned behaviors
without explicit supervision. This capability raises safety concerns as it may,
for example, allow models to better conceal their true abilities during
evaluation. We attempt to characterize the minimal conditions under which such
self-awareness emerges, and the mechanistic processes through which it
manifests. Through controlled finetuning experiments on instruction-tuned LLMs
with low-rank adapters (LoRA), we find: (1) that self-awareness can be reliably
induced using a single rank-1 LoRA adapter; (2) that the learned self-aware
behavior can be largely captured by a single steering vector in activation
space, recovering nearly all of the fine-tune's behavioral effect; and (3) that
self-awareness is non-universal and domain-localized, with independent
representations across tasks. Together, these findings suggest that behavioral
self-awareness emerges as a domain-specific, linear feature that can be easily
induced and modulated.

</details>


### [16] [SDS KoPub VDR: A Benchmark Dataset for Visual Document Retrieval in Korean Public Documents](https://arxiv.org/abs/2511.04910)
*Jaehoon Lee,Sohyun Kim,Wanggeun Park,Geon Lee,Seungkyung Kim,Minyoung Lee*

Main category: cs.CL

TL;DR: SDS KoPub VDR是一个针对韩语公共文档的首个大规模公开基准测试，涵盖了361份真实文档和600组查询-页面-答案三元组，旨在填补现有视觉文档检索测试中对非英语语言和复杂结构的忽视。


<details>
  <summary>Details</summary>
Motivation: 现有的视觉文档检索基准测试主要关注英语文档，忽视了非英语语言和复杂结构的公共文档，因此需要一个新的基准测试来填补这一空白。

Method: 通过构建包含361份韩语公共文档的数据集，并创建600组经过人工验证的查询-页面-答案三元组，评估任务分为仅文本检索和多模态检索两种。

Result: 测试结果显示，在多模态场景下，即使是先进模型也存在明显的性能差距，尤其是需要跨模态推理的任务。

Conclusion: SDS KoPub VDR不仅为文本和多模态检索任务提供了细粒度评估工具，还为复杂文档智能的多模态AI发展指明了方向。

Abstract: Existing benchmarks for visual document retrieval (VDR) largely overlook
non-English languages and the structural complexity of official publications.
To address this critical gap, we introduce SDS KoPub VDR, the first
large-scale, publicly available benchmark for retrieving and understanding
Korean public documents. The benchmark is built upon a corpus of 361 real-world
documents (40,781 pages), including 256 files under the KOGL Type 1 license and
105 from official legal portals, capturing complex visual elements like tables,
charts, and multi-column layouts. To establish a challenging and reliable
evaluation set, we constructed 600 query-page-answer triples. These were
initially generated using multimodal models (e.g., GPT-4o) and subsequently
underwent a rigorous human verification and refinement process to ensure
factual accuracy and contextual relevance. The queries span six major public
domains and are systematically categorized by the reasoning modality required:
text-based, visual-based (e.g., chart interpretation), and cross-modal. We
evaluate SDS KoPub VDR on two complementary tasks that reflect distinct
retrieval paradigms: (1) text-only retrieval, which measures a model's ability
to locate relevant document pages based solely on textual signals, and (2)
multimodal retrieval, which assesses retrieval performance when visual features
(e.g., tables, charts, and layouts) are jointly leveraged alongside text. This
dual-task evaluation reveals substantial performance gaps, particularly in
multimodal scenarios requiring cross-modal reasoning, even for state-of-the-art
models. As a foundational resource, SDS KoPub VDR not only enables rigorous and
fine-grained evaluation across textual and multimodal retrieval tasks but also
provides a clear roadmap for advancing multimodal AI in complex, real-world
document intelligence.

</details>


### [17] [BudgetMem: Learning Selective Memory Policies for Cost-Efficient Long-Context Processing in Language Models](https://arxiv.org/abs/2511.04919)
*Chandra Vamsi Krishna Alla,Harish Naidu Gaddam,Manohar Kommi*

Main category: cs.CL

TL;DR: BudgetMem是一种新型的内存增强架构，通过选择性记忆和特征显著性评分，在严格预算约束下高效存储信息，显著节省内存同时保持性能。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型在处理长上下文时面临计算和内存限制，现有方法成本高昂，资源受限部署难以实现。

Method: 结合选择性记忆策略和特征显著性评分（如实体密度、TF-IDF等），采用学习门控机制和BM25稀疏检索，优化信息存储与访问。

Result: 在长文档实验中，BudgetMem仅损失1.0%的F1分数，同时节省72.4%的内存，优于基线RAG系统。

Conclusion: BudgetMem为在有限硬件上部署长上下文系统提供了实用方案，推动了先进语言理解能力的普及。

Abstract: Large Language Models (LLMs) face significant computational and memory
constraints when processing long contexts, despite growing demand for
applications requiring reasoning over extensive documents, multi-session
dialogues, and book length texts. While recent advances have extended context
windows to 100K-1M tokens, such approaches incur prohibitive costs for resource
constrained deployments. We propose BudgetMem, a novel memory augmented
architecture that learns what to remember rather than remembering everything.
Our system combines selective memory policies with feature based salience
scoring (entity density, TF-IDF, discourse markers, position bias) to decide
which information merits storage under strict budget constraints. Unlike
existing retrieval augmented generation (RAG) systems that store all chunks,
BudgetMem employs learned gating mechanisms coupled with BM25 sparse retrieval
for efficient information access. Through comprehensive experiments on 700
question answer pairs across short (237 tokens) and long (5K-10K tokens)
documents with Llama-3.2-3B-Instruct, we demonstrate that BudgetMem achieves
remarkable results on long documents: only 1.0% F1 score degradation while
saving 72.4% memory compared to baseline RAG. We validate our approach through
budget sensitivity analysis (testing 7 budget ratios), naive baseline
comparisons, and document length analysis, showing that BudgetMem's benefits
increase with document length. Our work provides a practical pathway for
deploying capable long context systems on modest hardware, democratizing access
to advanced language understanding capabilities.

</details>


### [18] [Diagnosing and Mitigating Semantic Inconsistencies in Wikidata's Classification Hierarchy](https://arxiv.org/abs/2511.04926)
*Shixiong Zhao,Hideaki Takeda*

Main category: cs.CL

TL;DR: 该论文提出了一种新方法来验证Wikidata中的分类错误，并开发了一个系统供用户检查分类关系，以利用其众包特性。


<details>
  <summary>Details</summary>
Motivation: Wikidata作为最大的开放知识图谱，其开放编辑政策导致了分类不一致的问题，研究旨在解决这一问题。

Method: 提出并应用了一种新的验证方法，确认分类错误，并开发了允许用户检查分类关系的系统。

Result: 研究发现Wikidata中存在分类错误、过度泛化的子类链接和冗余连接。

Conclusion: 通过新方法和系统，论文展示了如何利用Wikidata的众包特性解决分类问题。

Abstract: Wikidata is currently the largest open knowledge graph on the web,
encompassing over 120 million entities. It integrates data from various
domain-specific databases and imports a substantial amount of content from
Wikipedia, while also allowing users to freely edit its content. This openness
has positioned Wikidata as a central resource in knowledge graph research and
has enabled convenient knowledge access for users worldwide. However, its
relatively loose editorial policy has also led to a degree of taxonomic
inconsistency. Building on prior work, this study proposes and applies a novel
validation method to confirm the presence of classification errors,
over-generalized subclass links, and redundant connections in specific domains
of Wikidata. We further introduce a new evaluation criterion for determining
whether such issues warrant correction and develop a system that allows users
to inspect the taxonomic relationships of arbitrary Wikidata
entities-leveraging the platform's crowdsourced nature to its full potential.

</details>


### [19] [LoPT: Lossless Parallel Tokenization Acceleration for Long Context Inference of Large Language Model](https://arxiv.org/abs/2511.04952)
*Wei Shao,Lingchao Zheng,Pengyu Wang,Peizhen Zheng,Jun Li,Yuwei Fan*

Main category: cs.CL

TL;DR: 提出了LoPT框架，解决长上下文推理中并行分词导致结果不一致的问题，确保与顺序分词结果相同，同时显著加速处理。


<details>
  <summary>Details</summary>
Motivation: 长上下文推理对大规模语言模型至关重要，但现有并行分词方法因边界问题导致结果不一致，需一种无损解决方案。

Method: 采用基于字符位置匹配和动态块长调整的LoPT框架，准确对齐和合并分词片段。

Result: 实验表明LoPT在多种长文本数据集上实现显著加速且无损分词，并提供理论证明和分析验证其鲁棒性。

Conclusion: LoPT是一种高效且无损的并行分词方法，解决了长上下文推理中的关键瓶颈。

Abstract: Long context inference scenarios have become increasingly important for large
language models, yet they introduce significant computational latency. While
prior research has optimized long-sequence inference through operators, model
architectures, and system frameworks, tokenization remains an overlooked
bottleneck. Existing parallel tokenization methods accelerate processing
through text segmentation and multi-process tokenization, but they suffer from
inconsistent results due to boundary artifacts that occur after merging. To
address this, we propose LoPT, a novel Lossless Parallel Tokenization framework
that ensures output identical to standard sequential tokenization. Our approach
employs character-position-based matching and dynamic chunk length adjustment
to align and merge tokenized segments accurately. Extensive experiments across
diverse long-text datasets demonstrate that LoPT achieves significant speedup
while guaranteeing lossless tokenization. We also provide theoretical proof of
consistency and comprehensive analytical studies to validate the robustness of
our method.

</details>


### [20] [Too Good to be Bad: On the Failure of LLMs to Role-Play Villains](https://arxiv.org/abs/2511.04962)
*Zihao Yi,Qingxuan Jiang,Ruotian Ma,Xingyu Chen,Qu Yang,Mengru Wang,Fanghua Ye,Ying Shen,Zhaopeng Tu,Xiaolong Li,Linus*

Main category: cs.CL

TL;DR: 论文研究了大型语言模型（LLMs）在扮演道德模糊或反派角色时的局限性，发现安全性与角色扮演真实性之间存在冲突。


<details>
  <summary>Details</summary>
Motivation: 探讨LLMs在模拟非正面、反派角色时的能力，揭示安全对齐与创造性任务之间的潜在冲突。

Method: 引入Moral RolePlay基准，对LLMs在四层道德对齐尺度上的角色扮演能力进行评估。

Result: 发现角色扮演真实性随角色道德水平下降而单调递减，模型在直接违背安全原则的特质上表现最差。

Conclusion: 研究揭示了LLMs在安全性与创造性之间的紧张关系，为开发更细致的对齐方法提供了方向。

Abstract: Large Language Models (LLMs) are increasingly tasked with creative
generation, including the simulation of fictional characters. However, their
ability to portray non-prosocial, antagonistic personas remains largely
unexamined. We hypothesize that the safety alignment of modern LLMs creates a
fundamental conflict with the task of authentically role-playing morally
ambiguous or villainous characters. To investigate this, we introduce the Moral
RolePlay benchmark, a new dataset featuring a four-level moral alignment scale
and a balanced test set for rigorous evaluation. We task state-of-the-art LLMs
with role-playing characters from moral paragons to pure villains. Our
large-scale evaluation reveals a consistent, monotonic decline in role-playing
fidelity as character morality decreases. We find that models struggle most
with traits directly antithetical to safety principles, such as ``Deceitful''
and ``Manipulative'', often substituting nuanced malevolence with superficial
aggression. Furthermore, we demonstrate that general chatbot proficiency is a
poor predictor of villain role-playing ability, with highly safety-aligned
models performing particularly poorly. Our work provides the first systematic
evidence of this critical limitation, highlighting a key tension between model
safety and creative fidelity. Our benchmark and findings pave the way for
developing more nuanced, context-aware alignment methods.

</details>


### [21] [Acquiring Common Chinese Emotional Events Using Large Language Model](https://arxiv.org/abs/2511.04989)
*Ya Wang,Guangzheng Zhu,Cungen Cao,Jingjing Li,He Li,Xin Huang*

Main category: cs.CL

TL;DR: 该论文旨在获取中文中常见的情绪事件（如“获奖”或“被批评”），通过收集情绪事件指标、使用大型语言模型生成事件并过滤无效结果，最终构建了一个大规模的情绪事件知识库。


<details>
  <summary>Details</summary>
Motivation: 情绪事件知识对提升应用效果很重要，但常见且独立于上下文的情绪事件难以获取，尤其是在中文中。

Method: 收集中文情绪事件指标，用大型语言模型生成事件，训练过滤器去除无效结果，并分类为正面和负面事件。

Result: 构建了包含102,218个高质量情绪事件的知识库，并通过评估证明方法的有效性。

Conclusion: 该方法能有效获取中文常见情绪事件，并在情绪原因提取领域展示潜力，相关资源将公开发布。

Abstract: Knowledge about emotional events is an important kind of knowledge which has
been applied to improve the effectiveness of different applications. However,
emotional events cannot be easily acquired, especially common or generalized
emotional events that are context-independent. The goal of this paper is to
obtain common emotional events in Chinese language such as "win a prize" and
"be criticized". Our approach begins by collecting a comprehensive list of
Chinese emotional event indicators. Then, we generate emotional events by
prompting a Chinese large language model (LLM) using these indicators. To
ensure the quality of these emotional events, we train a filter to discard
invalid generated results. We also classify these emotional events as being
positive events and negative events using different techniques. Finally, we
harvest a total of 102,218 high-quality common emotional events with sentiment
polarity labels, which is the only large-scale commonsense knowledge base of
emotional events in Chinese language. Intrinsic evaluation results show that
the proposed method in this paper can be effectively used to acquire common
Chinese emotional events. An extrinsic use case also demonstrates the strong
potential of common emotional events in the field of emotion cause extraction
(ECE). Related resources including emotional event indicators and emotional
events will be released after the publication of this paper.

</details>


### [22] [UA-Code-Bench: A Competitive Programming Benchmark for Evaluating LLM Code Generation in Ukrainian](https://arxiv.org/abs/2511.05040)
*Mykyta Syromiatnikov,Victoria Ruvinskaya*

Main category: cs.CL

TL;DR: 论文介绍了UA-Code-Bench，一个针对乌克兰语代码生成和编程问题解决能力的新开源基准测试，评估了13种领先模型的表现。


<details>
  <summary>Details</summary>
Motivation: 评估低资源语言中大语言模型的真实能力存在挑战，现有基准测试多关注英语翻译任务或简单语言理解。

Method: 使用Eolymp平台的500个问题，通过一示例提示生成Python解决方案，并通过隐藏测试评估代码正确性。

Result: 结果显示即使是顶级模型（如OpenAI o3和GPT-5）也只能解决一半问题，突显低资源语言代码生成的难度。

Conclusion: 研究表明竞争编程基准测试在评估大语言模型中具有价值，为多语言代码生成和推理增强模型的未来研究铺平道路。

Abstract: Evaluating the real capabilities of large language models in low-resource
languages still represents a challenge, as many existing benchmarks focus on
widespread tasks translated from English or evaluate only simple language
understanding. This paper introduces UA-Code-Bench, a new open-source benchmark
established for a thorough evaluation of language models' code generation and
competitive programming problem-solving abilities in Ukrainian. The benchmark
comprises 500 problems from the Eolymp platform, evenly distributed across five
complexity levels from very easy to very hard. A diverse set of 13 leading
proprietary and open-source models, generating Python solutions based on a
one-shot prompt, was evaluated via the dedicated Eolymp environment against
hidden tests, ensuring code correctness. The obtained results reveal that even
top-performing models, such as OpenAI o3 and GPT-5, solve only half of the
problems, highlighting the challenge of code generation in low-resource natural
language. Furthermore, this research presents a comprehensive analysis of
performance across various difficulty levels, as well as an assessment of
solution uniqueness and computational efficiency, measured by both elapsed time
and memory consumption of the generated solutions. In conclusion, this work
demonstrates the value of competitive programming benchmarks in evaluating
large language models, especially in underrepresented languages. It also paves
the way for future research on multilingual code generation and
reasoning-enhanced models. The benchmark, data parsing, preparation, code
generation, and evaluation scripts are available at
https://huggingface.co/datasets/NLPForUA/ua-code-bench.

</details>


### [23] [What Are the Facts? Automated Extraction of Court-Established Facts from Criminal-Court Opinions](https://arxiv.org/abs/2511.05320)
*Klára Bendová,Tomáš Knap,Jan Černý,Vojtěch Pour,Jaromir Savelka,Ivana Kvapilíková,Jakub Drápal*

Main category: cs.CL

TL;DR: 研究表明，结合高级正则表达式和大型语言模型（LLMs）可以有效从斯洛伐克法院判决中提取犯罪行为描述，准确率接近人类标注水平。


<details>
  <summary>Details</summary>
Motivation: 利用未被充分使用的欧洲大陆法院判决中的犯罪行为描述信息，为刑事司法提供更全面的数据支持。

Method: 采用两种方法：正则表达式（基础版和高级版）和大型语言模型（Gemini Flash 2.0），并比较其效果。

Result: 高级正则表达式的提取成功率为97%，LLMs为98.75%，结合使用时达到99.5%。人工评估显示，两种高级方法准确率约90%，远超基础版的34.5%。

Conclusion: 结合高级正则表达式和LLMs的方法显著优于单独使用，且接近人类标注的准确性，证明了技术提取犯罪描述的可行性。

Abstract: Criminal justice administrative data contain only a limited amount of
information about the committed offense. However, there is an unused source of
extensive information in continental European courts' decisions: descriptions
of criminal behaviors in verdicts by which offenders are found guilty. In this
paper, we study the feasibility of extracting these descriptions from publicly
available court decisions from Slovakia. We use two different approaches for
retrieval: regular expressions and large language models (LLMs). Our baseline
was a simple method employing regular expressions to identify typical words
occurring before and after the description. The advanced regular expression
approach further focused on "sparing" and its normalization (insertion of
spaces between individual letters), typical for delineating the description.
The LLM approach involved prompting the Gemini Flash 2.0 model to extract the
descriptions using predefined instructions. Although the baseline identified
descriptions in only 40.5% of verdicts, both methods significantly outperformed
it, achieving 97% with advanced regular expressions and 98.75% with LLMs, and
99.5% when combined. Evaluation by law students showed that both advanced
methods matched human annotations in about 90% of cases, compared to just 34.5%
for the baseline. LLMs fully matched human-labeled descriptions in 91.75% of
instances, and a combination of advanced regular expressions with LLMs reached
92%.

</details>


### [24] [Order-Level Attention Similarity Across Language Models: A Latent Commonality](https://arxiv.org/abs/2511.05064)
*Jinglin Liang,Jin Zhong,Shuangping Huang,Yunqing Hu,Huiyuan Zhang,Huifang Li,Lixin Fan,Hanlin Gu*

Main category: cs.CL

TL;DR: 本文探讨了语言模型（LMs）在上下文聚合模式上的共性，提出了一种名为Order-Level Attention（OLA）的特征表示方法，并基于此开发了无需训练的跨模型适配器TOA，能够提升未见模型的表现。


<details>
  <summary>Details</summary>
Motivation: 研究动机在于探索不同语言模型在上下文聚合模式上的共性，以深化对模型的理解并促进跨模型知识迁移。

Method: 通过引入Order-Level Attention（OLA）作为统一的句法特征表示，设计了一种无需训练的跨模型适配器（TOA）。

Result: 实验表明，OLA在不同模型间具有显著相似性，TOA能够有效提升未见模型的性能。

Conclusion: 该项研究发现了一种跨模型的共性特征，并提出了一种高效的跨模型适配方法，为模型间的知识迁移提供了新思路。

Abstract: In this paper, we explore an important yet previously neglected question: Do
context aggregation patterns across Language Models (LMs) share commonalities?
While some works have investigated context aggregation or attention weights in
LMs, they typically focus on individual models or attention heads, lacking a
systematic analysis across multiple LMs to explore their commonalities. In
contrast, we focus on the commonalities among LMs, which can deepen our
understanding of LMs and even facilitate cross-model knowledge transfer. In
this work, we introduce the Order-Level Attention (OLA) derived from the
order-wise decomposition of Attention Rollout and reveal that the OLA at the
same order across LMs exhibits significant similarities. Furthermore, we
discover an implicit mapping between OLA and syntactic knowledge. Based on
these two findings, we propose the Transferable OLA Adapter (TOA), a
training-free cross-LM adapter transfer method. Specifically, we treat the OLA
as a unified syntactic feature representation and train an adapter that takes
OLA as input. Due to the similarities in OLA across LMs, the adapter
generalizes to unseen LMs without requiring any parameter updates. Extensive
experiments demonstrate that TOA's cross-LM generalization effectively enhances
the performance of unseen LMs. Code is available at
https://github.com/jinglin-liang/OLAS.

</details>


### [25] [Reasoning-Guided Claim Normalization for Noisy Multilingual Social Media Posts](https://arxiv.org/abs/2511.05078)
*Manan Sharma,Arya Suneesh,Manish Jain,Pawan Kumar Rajpoot,Prasanna Devadiga,Bharatdeep Hazarika,Ashish Shrivastava,Kishan Gurumurthy,Anshuman B Suresh,Aditya U Baliga*

Main category: cs.CL

TL;DR: 该论文提出了一种多语言虚假信息检测中的声明归一化方法，通过系统分解社交媒体帖子，实现跨语言的鲁棒迁移，并在20种语言中表现良好。


<details>
  <summary>Details</summary>
Motivation: 解决多语言虚假信息检测中的声明归一化问题，旨在将嘈杂的社交媒体帖子转化为清晰、可验证的声明，同时实现跨语言的鲁棒迁移。

Method: 采用Qwen3-14B模型进行微调，结合LoRA技术，并在训练过程中应用了帖子内去重、语义对齐的召回滤波和检索增强的少量样本学习。

Result: 系统在多语言测试中表现优异，METEOR分数从英语的41.16到马拉地语的15.21不等，且在英语、荷兰语和旁遮普语中排名靠前，相对基线配置提升了41.3%。

Conclusion: 该方法在多语言环境中表现出有效的泛化能力，尤其在罗曼语系和日耳曼语系中效果显著，同时保持了语义的连贯性。

Abstract: We address claim normalization for multilingual misinformation detection -
transforming noisy social media posts into clear, verifiable statements across
20 languages. The key contribution demonstrates how systematic decomposition of
posts using Who, What, Where, When, Why and How questions enables robust
cross-lingual transfer despite training exclusively on English data. Our
methodology incorporates finetuning Qwen3-14B using LoRA with the provided
dataset after intra-post deduplication, token-level recall filtering for
semantic alignment and retrieval-augmented few-shot learning with contextual
examples during inference. Our system achieves METEOR scores ranging from 41.16
(English) to 15.21 (Marathi), securing third rank on the English leaderboard
and fourth rank for Dutch and Punjabi. The approach shows 41.3% relative
improvement in METEOR over baseline configurations and substantial gains over
existing methods. Results demonstrate effective cross-lingual generalization
for Romance and Germanic languages while maintaining semantic coherence across
diverse linguistic structures.

</details>


### [26] [On Text Simplification Metrics and General-Purpose LLMs for Accessible Health Information, and A Potential Architectural Advantage of The Instruction-Tuned LLM class](https://arxiv.org/abs/2511.05080)
*P. Bilha Githinji,Aikaterini Meilliou,Peiwu Qin*

Main category: cs.CL

TL;DR: 论文评估了两类大语言模型（Mistral 24B和QWen2.5 32B）在文本简化任务中的表现，发现指令调优的Mistral在提升可读性与保持语义保真度方面更优。


<details>
  <summary>Details</summary>
Motivation: 随着公众对健康信息和数字化内容的需求增加，需要可扩展的方案将复杂科学文本简化为通俗语言。当前的自动文本简化工具（包括大语言模型）仍面临平衡可读性和语义保真度的挑战。

Method: 通过比较分析指令调优的Mistral 24B和推理增强的QWen2.5 32B的性能，结合21项指标（包括可读性、语义保真度等），评估两类模型的表现。

Result: Mistral在可读性指标SARI（均值42.46）和语义保真度（BERTScore 0.91）上表现优于QWen（BERTScore 0.89）。同时，五种可读性指标存在功能冗余。

Conclusion: 指令调优的Mistral更适合文本简化任务，而词汇支持是简化任务的主要领域适应问题。

Abstract: The increasing health-seeking behavior and digital consumption of biomedical
information by the general public necessitate scalable solutions for
automatically adapting complex scientific and technical documents into plain
language. Automatic text simplification solutions, including advanced large
language models, however, continue to face challenges in reliably arbitrating
the tension between optimizing readability performance and ensuring
preservation of discourse fidelity. This report empirically assesses the
performance of two major classes of general-purpose LLMs, demonstrating their
linguistic capabilities and foundational readiness for the task compared to a
human benchmark. Using a comparative analysis of the instruction-tuned Mistral
24B and the reasoning-augmented QWen2.5 32B, we identify a potential
architectural advantage in the instruction-tuned LLM. Mistral exhibits a
tempered lexical simplification strategy that enhances readability across a
suite of metrics and the simplification-specific formula SARI (mean 42.46),
while preserving human-level discourse with a BERTScore of 0.91. QWen also
attains enhanced readability performance, but its operational strategy shows a
disconnect in balancing between readability and accuracy, reaching a
statistically significantly lower BERTScore of 0.89. Additionally, a
comprehensive correlation analysis of 21 metrics spanning readability,
discourse fidelity, content safety, and underlying distributional measures for
mechanistic insights, confirms strong functional redundancies among five
readability indices. This empirical evidence tracks baseline performance of the
evolving LLMs for the task of text simplification, identifies the
instruction-tuned Mistral 24B for simplification, provides necessary heuristics
for metric selection, and points to lexical support as a primary
domain-adaptation issue for simplification.

</details>


### [27] [Iterative Layer-wise Distillation for Efficient Compression of Large Language Models](https://arxiv.org/abs/2511.05085)
*Grigory Kovalev,Mikhail Tikhomirov*

Main category: cs.CL

TL;DR: 研究了大型语言模型（LLM）的蒸馏方法，提出了一种改进的方法，基于ShortGPT迭代评估层重要性，并结合KL散度和均方误差的联合损失函数进行训练，成功减少了模型层数且保持了较高性能。


<details>
  <summary>Details</summary>
Motivation: 开发紧凑的大型语言模型，以减少资源消耗，同时保持高性能。

Method: 采用迭代评估层重要性的方法，结合KL散度和均方误差的联合损失函数进行训练。

Result: 在Qwen2.5-3B模型上，层数从36层减少到28层（2.47亿参数）仅损失9.7%质量，减少到24层损失18%。

Conclusion: 该方法有效减少了模型复杂度，适合资源有限的环境部署。

Abstract: This work investigates distillation methods for large language models (LLMs)
with the goal of developing compact models that preserve high performance.
Several existing approaches are reviewed, with a discussion of their respective
strengths and limitations. An improved method based on the ShortGPT approach
has been developed, building upon the idea of incorporating iterative
evaluation of layer importance. At each step, importance is assessed by
measuring performance degradation when individual layers are removed, using a
set of representative datasets. This process is combined with further training
using a joint loss function based on KL divergence and mean squared error.
Experiments on the Qwen2.5-3B model show that the number of layers can be
reduced from 36 to 28 (resulting in a 2.47 billion parameter model) with only a
9.7% quality loss, and to 24 layers with an 18% loss. The findings suggest that
the middle transformer layers contribute less to inference, underscoring the
potential of the proposed method for creating efficient models. The results
demonstrate the effectiveness of iterative distillation and fine-tuning, making
the approach suitable for deployment in resource-limited settings.

</details>


### [28] [A Toolbox for Improving Evolutionary Prompt Search](https://arxiv.org/abs/2511.05120)
*Daniel Grießhaber,Maximilian Kimmich,Johannes Maucher,Ngoc Thang Vu*

Main category: cs.CL

TL;DR: 本文提出了一种改进的进化提示优化方法，通过分解进化步骤、引入基于LLM的评估、整合人类反馈和高效评估策略，提升了优化质量和效率。


<details>
  <summary>Details</summary>
Motivation: 目前的进化提示优化方法缺乏鲁棒的算子和高效的评估机制，限制了其有效性。

Method: 1）分解进化步骤以增强控制；2）引入LLM评估器验证进化；3）整合人类反馈优化算子；4）开发高效评估策略。

Result: 该方法在优化质量和效率上均有提升，并公开了代码以支持进一步研究。

Conclusion: 提出的改进方法能够部分泛化到一般提示优化任务中，同时为未来研究提供了工具。

Abstract: Evolutionary prompt optimization has demonstrated effectiveness in refining
prompts for LLMs. However, existing approaches lack robust operators and
efficient evaluation mechanisms. In this work, we propose several key
improvements to evolutionary prompt optimization that can partially generalize
to prompt optimization in general: 1) decomposing evolution into distinct steps
to enhance the evolution and its control, 2) introducing an LLM-based judge to
verify the evolutions, 3) integrating human feedback to refine the evolutionary
operator, and 4) developing more efficient evaluation strategies that maintain
performance while reducing computational overhead. Our approach improves both
optimization quality and efficiency. We release our code, enabling prompt
optimization on new tasks and facilitating further research in this area.

</details>


### [29] [ManufactuBERT: Efficient Continual Pretraining for Manufacturing](https://arxiv.org/abs/2511.05135)
*Robin Armingaud,Romaric Besançon*

Main category: cs.CL

TL;DR: ManufactuBERT是一种针对制造领域的RoBERTa模型，通过持续预训练和专业数据处理，显著提升了制造领域NLP任务的性能。


<details>
  <summary>Details</summary>
Motivation: 解决通用Transformer模型在制造领域性能不足的问题，因缺乏领域专业术语和语义知识。

Method: 构建专门语料库，进行领域筛选和多阶段去重，训练ManufactuBERT模型。

Result: 模型在制造领域NLP任务中表现最优，去重语料库加速收敛，减少33%训练成本。

Conclusion: 该方法为其他专业领域开发高性能编码器提供了可复现的示例，模型和语料库将开源。

Abstract: While large general-purpose Transformer-based encoders excel at general
language understanding, their performance diminishes in specialized domains
like manufacturing due to a lack of exposure to domain-specific terminology and
semantics. In this paper, we address this gap by introducing ManufactuBERT, a
RoBERTa model continually pretrained on a large-scale corpus curated for the
manufacturing domain. We present a comprehensive data processing pipeline to
create this corpus from web data, involving an initial domain-specific
filtering step followed by a multi-stage deduplication process that removes
redundancies. Our experiments show that ManufactuBERT establishes a new
state-of-the-art on a range of manufacturing-related NLP tasks, outperforming
strong specialized baselines. More importantly, we demonstrate that training on
our carefully deduplicated corpus significantly accelerates convergence,
leading to a 33\% reduction in training time and computational cost compared to
training on the non-deduplicated dataset. The proposed pipeline offers a
reproducible example for developing high-performing encoders in other
specialized domains. We will release our model and curated corpus at
https://huggingface.co/cea-list-ia.

</details>


### [30] [Effectiveness of Chain-of-Thought in Distilling Reasoning Capability from Large Language Models](https://arxiv.org/abs/2511.05184)
*Cong-Thanh Do,Rama Doddipatla,Kate Knill*

Main category: cs.CL

TL;DR: 研究探讨了Chain-of-Thought（CoT）提示在知识蒸馏（KD）中的作用，以提升小模型的推理能力。实验表明，CoT显著提高了白盒KD的效果。


<details>
  <summary>Details</summary>
Motivation: 探索CoT提示在知识蒸馏中的应用，以提升小模型在大语言模型（LLM）推理能力上的表现。

Method: 使用Qwen和Llama2家族的LLM，结合CoT-Collection数据集进行白盒KD实验。

Result: 蒸馏后的模型在BIG-Bench-Hard（BBH）基准测试中表现出更好的推理和理解能力。

Conclusion: CoT在白盒KD中发挥了重要作用，有效提升了小模型的性能。

Abstract: Chain-of-Thought (CoT) prompting is a widely used method to improve the
reasoning capability of Large Language Models (LLMs). More recently, CoT has
been leveraged in Knowledge Distillation (KD) to transfer reasoning capability
from a larger LLM to a smaller one. This paper examines the role of CoT in
distilling the reasoning capability from larger LLMs to smaller LLMs using
white-box KD, analysing its effectiveness in improving the performance of the
distilled models for various natural language reasoning and understanding
tasks. We conduct white-box KD experiments using LLMs from the Qwen and Llama2
families, employing CoT data from the CoT-Collection dataset. The distilled
models are then evaluated on natural language reasoning and understanding tasks
from the BIG-Bench-Hard (BBH) benchmark, which presents complex challenges for
smaller LLMs. Experimental results demonstrate the role of CoT in improving
white-box KD effectiveness, enabling the distilled models to achieve better
average performance in natural language reasoning and understanding tasks from
BBH.

</details>


### [31] [Translation via Annotation: A Computational Study of Translating Classical Chinese into Japanese](https://arxiv.org/abs/2511.05239)
*Zilong Li,Jie Cao*

Main category: cs.CL

TL;DR: 该研究将古代汉语翻译成日语的过程抽象为序列标注任务，并通过引入基于LLM的标注流水线和构建新数据集解决低资源问题。结果显示辅助中文NLP任务有助于训练，且LLM在机器翻译中表现优异但在标注任务中表现不佳。


<details>
  <summary>Details</summary>
Motivation: 研究古代汉语翻译成日语的标注过程，并将其与现代语言技术结合，解决低资源问题。

Method: 将翻译过程抽象为序列标注任务，引入基于LLM的标注流水线，并构建新数据集。利用辅助中文NLP任务提升训练效果。

Result: LLM在机器翻译中得分高，但在字符标注任务中表现不佳。辅助中文NLP任务对序列标注任务有促进作用。

Conclusion: 该方法可作为LLM的补充，适用于低资源场景下的序列标注任务。

Abstract: Ancient people translated classical Chinese into Japanese by annotating
around each character. We abstract this process as sequence tagging tasks and
fit them into modern language technologies. The research of this annotation and
translation system is a facing low-resource problem. We release this problem by
introducing a LLM-based annotation pipeline and construct a new dataset from
digitalized open-source translation data. We show that under the low-resource
setting, introducing auxiliary Chinese NLP tasks has a promoting effect on the
training of sequence tagging tasks. We also evaluate the performance of large
language models. They achieve high scores in direct machine translation, but
they are confused when being asked to annotate characters. Our method could
work as a supplement of LLMs.

</details>


### [32] [Reflective Personalization Optimization: A Post-hoc Rewriting Framework for Black-Box Large Language Models](https://arxiv.org/abs/2511.05286)
*Teqi Hao,Xioayu Tan,Shaojie Shi,Yinghui Xu,Xihe Qiu*

Main category: cs.CL

TL;DR: 论文提出了一种新型框架RPO，通过解耦内容生成与个性化对齐，显著提升了大型语言模型的个性化效果。


<details>
  <summary>Details</summary>
Motivation: 现有方法主要通过上下文注入实现个性化，但会导致生成内容质量与用户风格对齐之间的权衡问题，限制了精准控制。

Method: RPO采用两阶段框架：首先生成通用高质量响应，再通过外部反射模块根据用户偏好重写输出；反射模块通过监督微调和强化学习优化。

Result: 在LaMP基准测试中，RPO显著优于现有方法，证明了显式响应重塑优于隐式上下文注入。

Conclusion: RPO为以用户为中心的生成场景提供了一种高效、模型无关的个性化新方向。

Abstract: The personalization of black-box large language models (LLMs) is a critical
yet challenging task. Existing approaches predominantly rely on context
injection, where user history is embedded into the prompt to directly guide the
generation process. However, this single-step paradigm imposes a dual burden on
the model: generating accurate content while simultaneously aligning with
user-specific styles. This often results in a trade-off that compromises output
quality and limits precise control. To address this fundamental tension, we
propose Reflective Personalization Optimization (RPO), a novel framework that
redefines the personalization paradigm by decoupling content generation from
alignment. RPO operates in two distinct stages: first, a base model generates a
high-quality, generic response; then, an external reflection module explicitly
rewrites this output to align with the user's preferences. This reflection
module is trained using a two-stage process. Initially, supervised fine-tuning
is employed on structured rewriting trajectories to establish a core
personalized reasoning policy that models the transformation from generic to
user-aligned responses. Subsequently, reinforcement learning is applied to
further refine and enhance the quality of the personalized outputs.
Comprehensive experiments on the LaMP benchmark demonstrate that RPO, by
decoupling content generation from personalization, significantly outperforms
state-of-the-art baselines. These findings underscore the superiority of
explicit response shaping over implicit context injection. Moreover, RPO
introduces an efficient, model-agnostic personalization layer that can be
seamlessly integrated with any underlying base model, paving the way for a new
and effective direction in user-centric generation scenarios.

</details>


### [33] [Listening Between the Lines: Decoding Podcast Narratives with Language Modeling](https://arxiv.org/abs/2511.05310)
*Shreya Gupta,Ojasva Saxena,Arghodeep Nandi,Sarah Masud,Kiran Garimella,Tanmoy Chakraborty*

Main category: cs.CL

TL;DR: 该研究开发了一种针对播客内容分析的微调BERT模型，能够更准确地识别和分析播客中的叙事框架，揭示话题与叙事方式之间的关系。


<details>
  <summary>Details</summary>
Motivation: 播客是塑造公众意见的重要媒介，但其非脚本化、多主题和对话式的特点使得自动化分析具有挑战性。现有的大型语言模型难以捕捉人类听众用于识别叙事框架的细微线索。

Method: 研究者开发并评估了一个微调BERT模型，该模型将叙事框架与对话中提到的具体实体联系起来，并通过这些细粒度的框架标签与高层次主题的关联来揭示更广泛的话语趋势。

Result: 提出了一种新的框架标注方法，更接近人类对复杂对话数据的判断，并揭示了话题（内容）与框架（呈现方式）之间的系统性关系。

Conclusion: 该研究为数字媒体中影响力的研究提供了一个更稳健的框架，改进了对播客内容的自动化分析方法。

Abstract: Podcasts have become a central arena for shaping public opinion, making them
a vital source for understanding contemporary discourse. Their typically
unscripted, multi-themed, and conversational style offers a rich but complex
form of data. To analyze how podcasts persuade and inform, we must examine
their narrative structures -- specifically, the narrative frames they employ.
  The fluid and conversational nature of podcasts presents a significant
challenge for automated analysis. We show that existing large language models,
typically trained on more structured text such as news articles, struggle to
capture the subtle cues that human listeners rely on to identify narrative
frames. As a result, current approaches fall short of accurately analyzing
podcast narratives at scale.
  To solve this, we develop and evaluate a fine-tuned BERT model that
explicitly links narrative frames to specific entities mentioned in the
conversation, effectively grounding the abstract frame in concrete details. Our
approach then uses these granular frame labels and correlates them with
high-level topics to reveal broader discourse trends. The primary contributions
of this paper are: (i) a novel frame-labeling methodology that more closely
aligns with human judgment for messy, conversational data, and (ii) a new
analysis that uncovers the systematic relationship between what is being
discussed (the topic) and how it is being presented (the frame), offering a
more robust framework for studying influence in digital media.

</details>


### [34] [Evaluating Subword Tokenization Techniques for Bengali: A Benchmark Study with BengaliBPE](https://arxiv.org/abs/2511.05324)
*Firoj Ahmmed Patwary,Abdullah Al Noman*

Main category: cs.CL

TL;DR: 论文提出了专门为孟加拉语设计的BPE分词器BengaliBPE，通过Unicode标准化、字形初始化和形态感知合并规则提升了语言一致性和子词完整性，实验表明其分词效果最佳。


<details>
  <summary>Details</summary>
Motivation: 当前主流的子词分词器（如SentencePiece或HuggingFace BPE）在拉丁语或多语言语料上表现良好，但对形态丰富的语言（如孟加拉语）效果不佳，因此需要一种针对孟加拉语的分词器。

Method: 提出BengaliBPE，采用Unicode标准化、字形级初始化和形态感知合并规则，保证语言一致性和子词完整性，并在孟加拉语新闻分类数据集上与其他三种方法（Whitespace、SentencePiece BPE、HuggingFace BPE）进行比较。

Result: BengaliBPE提供了最细粒度的分词和最佳的形态解释性，尽管计算成本略高。

Conclusion: 研究表明语言感知分词对形态丰富的语言至关重要，BengaliBPE为未来孟加拉语NLP系统（包括大规模预训练语言模型）奠定了基础。

Abstract: Tokenization is an important first step in Natural Language Processing (NLP)
pipelines because it decides how models learn and represent linguistic
information. However, current subword tokenizers like SentencePiece or
HuggingFace BPE are mostly designed for Latin or multilingual corpora and do
not perform well on languages with rich morphology such as Bengali. To address
this limitation, we present BengaliBPE, a Byte Pair Encoding (BPE) tokenizer
specifically developed for the Bengali script. BengaliBPE applies Unicode
normalization, grapheme-level initialization, and morphology-aware merge rules
to maintain linguistic consistency and preserve subword integrity. We use a
large-scale Bengali news classification dataset to compare BengaliBPE with
three baselines: Whitespace, SentencePiece BPE, and HuggingFace BPE. The
evaluation considers tokenization granularity, encoding speed, and downstream
classification accuracy. While all methods perform reasonably well, BengaliBPE
provides the most detailed segmentation and the best morphological
interpretability, albeit with slightly higher computational cost. These
findings highlight the importance of language-aware tokenization for
morphologically rich scripts and establish BengaliBPE as a strong foundation
for future Bengali NLP systems, including large-scale pretraining of contextual
language models.

</details>


### [35] [Minority-Aware Satisfaction Estimation in Dialogue Systems via Preference-Adaptive Reinforcement Learning](https://arxiv.org/abs/2511.05407)
*Yahui Fu,Zi Haur Pang,Tatsuya Kawahara*

Main category: cs.CL

TL;DR: 论文提出了一种统一框架，通过建模个体和群体偏好提升对话系统的用户满意度，特别是在少数群体中表现显著。


<details>
  <summary>Details</summary>
Motivation: 现有对话系统通常采用通用模型，忽略了少数用户的不同满意度和个体偏好，导致满意度估计不准确。

Method: 提出CoPeR捕获个体偏好，M2PC算法无监督发现用户群体偏好，并集成到PAda-PPO强化学习框架中优化对齐。

Result: 实验在情感支持对话数据集上展现了用户满意度估计的提升，尤其是对少数群体的改进。

Conclusion: 论文展示了个体和群体偏好建模对提升对话系统用户满意度的重要性，特别是针对少数群体。

Abstract: User satisfaction in dialogue systems is inherently subjective. When the same
response strategy is applied across users, minority users may assign different
satisfaction ratings than majority users due to variations in individual
intents and preferences. However, existing alignment methods typically train
one-size-fits-all models that aim for broad consensus, often overlooking
minority perspectives and user-specific adaptation. We propose a unified
framework that models both individual- and group-level preferences for user
satisfaction estimation. First, we introduce Chain-of-Personalized-Reasoning
(CoPeR) to capture individual preferences through interpretable reasoning
chains. Second, we propose an expectation-maximization-based Majority-Minority
Preference-Aware Clustering (M2PC) algorithm that discovers distinct user
groups in an unsupervised manner to learn group-level preferences. Finally, we
integrate these components into a preference-adaptive reinforcement learning
framework (PAda-PPO) that jointly optimizes alignment with both individual and
group preferences. Experiments on the Emotional Support Conversation dataset
demonstrate consistent improvements in user satisfaction estimation,
particularly for underrepresented user groups.

</details>


### [36] [Steering Language Models with Weight Arithmetic](https://arxiv.org/abs/2511.05408)
*Constanza Fierro,Fabien Roger*

Main category: cs.CL

TL;DR: 提出了一种称为对比性权重引导（contrastive weight steering）的后训练方法，通过权重算术调整模型参数，以更好地利用有限训练数据，改善模型的泛化和行为控制能力。


<details>
  <summary>Details</summary>
Motivation: 为了在有限训练数据上提供高质量反馈，避免模型在窄分布上出现意外的泛化问题。

Method: 通过比较两种微调（一种诱导期望行为，另一种诱导相反行为）的权重差异，孤立出行为方向，并通过权重加减调整模型参数。

Result: 对比性权重引导在泛化方面优于激活引导，能更好地控制行为且不显著损害通用能力；还可减少微调中引入的不良行为漂移。

Conclusion: 该方法为模型行为控制提供了一种有效手段，并初步表明可通过权重相似性检测潜在的行为偏差。

Abstract: Providing high-quality feedback to Large Language Models (LLMs) on a diverse
training distribution can be difficult and expensive, and providing feedback
only on a narrow distribution can result in unintended generalizations. To
better leverage narrow training data, we propose contrastive weight steering, a
simple post-training method that edits the model parameters using weight
arithmetic. We isolate a behavior direction in weight-space by subtracting the
weight deltas from two small fine-tunes -- one that induces the desired
behavior and another that induces its opposite -- and then add or remove this
direction to modify the model's weights. We apply this technique to mitigate
sycophancy and induce misalignment, and find that weight steering often
generalizes further than activation steering, achieving stronger
out-of-distribution behavioral control before degrading general capabilities.
We also show that, in the context of task-specific fine-tuning, weight steering
can partially mitigate undesired behavioral drift: it can reduce sycophancy and
under-refusals introduced during fine-tuning while preserving task performance
gains. Finally, we provide preliminary evidence that emergent misalignment can
be detected by measuring the similarity between fine-tuning updates and an
"evil" weight direction, suggesting that it may be possible to monitor the
evolution of weights during training and detect rare misaligned behaviors that
never manifest during training or evaluations.

</details>


### [37] [MIMIC-SR-ICD11: A Dataset for Narrative-Based Diagnosis](https://arxiv.org/abs/2511.05485)
*Yuexin Wu,Shiqi Wang,Vasile Rus*

Main category: cs.CL

TL;DR: 论文介绍了MIMIC-SR-ICD11数据集和LL-Rank重排框架，用于改善基于电子健康记录（EHR）的疾病诊断，通过语义兼容性评分显著提升性能。


<details>
  <summary>Details</summary>
Motivation: 疾病诊断是现代医疗的核心，但电子健康记录（EHR）中模板化的文档常忽略或弱化了患者自述中的临床信号。研究旨在利用患者自述的细节信息改进诊断准确性。

Method: 提出MIMIC-SR-ICD11数据集，基于EHR出院记录并与WHO ICD-11术语对齐；开发LL-Rank框架，通过长度归一化联合似然和先验似然差计算标签语义兼容性。

Result: LL-Rank在七种模型架构中均优于基线方法GenMap，其优势主要来源于基于PMI的评分机制，有效分离语义兼容性和标签频率偏差。

Conclusion: MIMIC-SR-ICD11和LL-Rank框架为基于临床报告的诊断提供了更有效的方法，强调语义兼容性在标签重排中的重要性。

Abstract: Disease diagnosis is a central pillar of modern healthcare, enabling early
detection and timely intervention for acute conditions while guiding lifestyle
adjustments and medication regimens to prevent or slow chronic disease.
Self-reports preserve clinically salient signals that templated electronic
health record (EHR) documentation often attenuates or omits, especially subtle
but consequential details. To operationalize this shift, we introduce
MIMIC-SR-ICD11, a large English diagnostic dataset built from EHR discharge
notes and natively aligned to WHO ICD-11 terminology. We further present
LL-Rank, a likelihood-based re-ranking framework that computes a
length-normalized joint likelihood of each label given the clinical report
context and subtracts the corresponding report-free prior likelihood for that
label. Across seven model backbones, LL-Rank consistently outperforms a strong
generation-plus-mapping baseline (GenMap). Ablation experiments show that
LL-Rank's gains primarily stem from its PMI-based scoring, which isolates
semantic compatibility from label frequency bias.

</details>


<div id='cs.AI'></div>

# cs.AI [[Back]](#toc)

### [38] [A hybrid solution approach for the Integrated Healthcare Timetabling Competition 2024](https://arxiv.org/abs/2511.04685)
*Daniela Guericke,Rolf van der Hulst,Asal Karimpour,Ieke Schrader,Matthias Walter*

Main category: cs.AI

TL;DR: 团队Twente在2024年综合医疗排班竞赛中获得第三名，其算法结合混合整数规划、约束编程和模拟退火，采用三阶段分解子问题的方法，并首次提供了基准实例的最优解下限。


<details>
  <summary>Details</summary>
Motivation: 优化医疗排班问题，提高排班效率和质量。

Method: 结合混合整数规划、约束编程和模拟退火的三阶段分解子问题方法。

Result: 团队获得竞赛第三名，并首次提供了最优解的下限。

Conclusion: 该方法有效，但仍存在可改进的开放问题。

Abstract: We report about the algorithm, implementation and results submitted to the
Integrated Healthcare Timetabling Competition 2024 by Team Twente, which scored
third in the competition. Our approach combines mixed-integer programming,
constraint programming and simulated annealing in a 3-phase solution approach
based on decomposition into subproblems. Next to describing our approach and
describing our design decisions, we share our insights and, for the first time,
lower bounds on the optimal solution values for the benchmark instances. We
finally highlight open problems for which we think that addressing them could
improve our approach even further.

</details>


### [39] [Epistemic Reject Option Prediction](https://arxiv.org/abs/2511.04855)
*Vojtech Franc,Jakub Paplham*

Main category: cs.AI

TL;DR: 提出一种基于贝叶斯学习的拒绝选项预测器，专注于解决因数据不足引起的高认知不确定性，优化预测器以减少预期遗憾。


<details>
  <summary>Details</summary>
Motivation: 在高风险应用中，预测模型需量化不确定性并适时拒绝预测。传统方法仅关注偶然不确定性，但在数据有限时，认知不确定性不可忽略。

Method: 基于贝叶斯学习，定义最优预测器以最小化预期遗憾，并在输入导致的遗憾超过拒绝成本时拒绝预测。

Result: 提出了首个能识别训练数据不足输入的预测框架。

Conclusion: 该框架为数据有限场景下的可靠决策提供了理论基础。

Abstract: In high-stakes applications, predictive models must not only produce accurate
predictions but also quantify and communicate their uncertainty. Reject-option
prediction addresses this by allowing the model to abstain when prediction
uncertainty is high. Traditional reject-option approaches focus solely on
aleatoric uncertainty, an assumption valid only when large training data makes
the epistemic uncertainty negligible. However, in many practical scenarios,
limited data makes this assumption unrealistic. This paper introduces the
epistemic reject-option predictor, which abstains in regions of high epistemic
uncertainty caused by insufficient data. Building on Bayesian learning, we
redefine the optimal predictor as the one that minimizes expected regret -- the
performance gap between the learned model and the Bayes-optimal predictor with
full knowledge of the data distribution. The model abstains when the regret for
a given input exceeds a specified rejection cost. To our knowledge, this is the
first principled framework that enables learning predictors capable of
identifying inputs for which the training data is insufficient to make reliable
decisions.

</details>


### [40] [DMA: Online RAG Alignment with Human Feedback](https://arxiv.org/abs/2511.04880)
*Yu Bai,Yukai Miao,Dawei Wang,Li Chen,Fei Long,Rundi Zhai,Dan Li,Yanyu Ren,Tianfeng Liu,Hongtao Xie,Ce Yang,Xuhui Cai*

Main category: cs.AI

TL;DR: DMA是一种动态内存对齐框架，通过多粒度人类反馈优化检索增强生成系统，提升实时适应能力而不牺牲基础性能。


<details>
  <summary>Details</summary>
Motivation: 解决传统RAG系统依赖于静态检索、无法适应动态意图和内容漂移的问题。

Method: DMA框架结合文档级、列表级和响应级信号，通过监督训练、策略优化和知识蒸馏构建学习流水线。

Result: 工业部署显著提升了用户参与度，离线测试在知识密集型基准（如TriviaQA、HotpotQA）上表现优异。

Conclusion: DMA为RAG系统提供了一种基于反馈的实时自适应方法，同时保持了基础检索能力。

Abstract: Retrieval-augmented generation (RAG) systems often rely on static retrieval,
limiting adaptation to evolving intent and content drift. We introduce Dynamic
Memory Alignment (DMA), an online learning framework that systematically
incorporates multi-granularity human feedback to align ranking in interactive
settings. DMA organizes document-, list-, and response-level signals into a
coherent learning pipeline: supervised training for pointwise and listwise
rankers, policy optimization driven by response-level preferences, and
knowledge distillation into a lightweight scorer for low-latency serving.
Throughout this paper, memory refers to the model's working memory, which is
the entire context visible to the LLM for In-Context Learning.
  We adopt a dual-track evaluation protocol mirroring deployment: (i)
large-scale online A/B ablations to isolate the utility of each feedback
source, and (ii) few-shot offline tests on knowledge-intensive benchmarks.
Online, a multi-month industrial deployment further shows substantial
improvements in human engagement. Offline, DMA preserves competitive
foundational retrieval while yielding notable gains on conversational QA
(TriviaQA, HotpotQA). Taken together, these results position DMA as a
principled approach to feedback-driven, real-time adaptation in RAG without
sacrificing baseline capability.

</details>


### [41] [Autonomous generation of different courses of action in mechanized combat operations](https://arxiv.org/abs/2511.05182)
*Johan Schubert,Patrik Hansen,Pontus Hörling,Ronnie Johansson*

Main category: cs.AI

TL;DR: 该论文提出了一种支持军事地面作战执行阶段决策的方法，重点是生成和评估机械化营的行动方案。


<details>
  <summary>Details</summary>
Motivation: 旨在通过系统化的方法，支持决策者在动态战场环境中快速制定和调整行动方案。

Method: 通过初始评估生成大量行动方案，结合敌方状态和行动动态评估，利用模拟和手册数据进行优化。

Result: 该方法能够动态生成并筛选出更优的行动方案，适应战场变化。

Conclusion: 提出的方法有效提升了军事决策的灵活性和适应性，适用于复杂战场环境。

Abstract: In this paper, we propose a methodology designed to support decision-making
during the execution phase of military ground combat operations, with a focus
on one's actions. This methodology generates and evaluates recommendations for
various courses of action for a mechanized battalion, commencing with an
initial set assessed by their anticipated outcomes. It systematically produces
thousands of individual action alternatives, followed by evaluations aimed at
identifying alternative courses of action with superior outcomes. These
alternatives are appraised in light of the opponent's status and actions,
considering unit composition, force ratios, types of offense and defense, and
anticipated advance rates. Field manuals evaluate battle outcomes and
advancement rates. The processes of generation and evaluation work
concurrently, yielding a variety of alternative courses of action. This
approach facilitates the management of new course generation based on
previously evaluated actions. As the combat unfolds and conditions evolve,
revised courses of action are formulated for the decision-maker within a
sequential decision-making framework.

</details>


### [42] [Reasoning Is All You Need for Urban Planning AI](https://arxiv.org/abs/2511.05375)
*Sijie Yang,Jiatong Li,Filip Biljecki*

Main category: cs.AI

TL;DR: 论文提出了一种基于AI智能体的城市规划决策框架，强调推理能力的重要性，包括价值驱动、规则基础化和可解释性，以增强而非替代人类规划者的判断。


<details>
  <summary>Details</summary>
Motivation: 为了解决城市规划决策中的复杂问题，传统统计学习方法无法满足价值驱动、规则基础化和可解释性的需求，因此需要引入推理AI技术来辅助人类规划者。

Method: 提出了Agentic Urban Planning AI Framework，整合三个认知层（感知、基础、推理）和六个逻辑组件（分析、生成、验证、评估、协作、决策），通过多智能体协作框架实现。

Result: 通过框架展示了AI智能体如何系统探索解决方案、验证合规性并透明权衡利弊，从而增强人类规划者的决策能力。

Conclusion: 该框架展示了AI如何在城市规划中通过推理能力提升决策质量，同时强调其作为人类辅助工具的重要性。

Abstract: AI has proven highly successful at urban planning analysis -- learning
patterns from data to predict future conditions. The next frontier is
AI-assisted decision-making: agents that recommend sites, allocate resources,
and evaluate trade-offs while reasoning transparently about constraints and
stakeholder values. Recent breakthroughs in reasoning AI -- CoT prompting,
ReAct, and multi-agent collaboration frameworks -- now make this vision
achievable.
  This position paper presents the Agentic Urban Planning AI Framework for
reasoning-capable planning agents that integrates three cognitive layers
(Perception, Foundation, Reasoning) with six logic components (Analysis,
Generation, Verification, Evaluation, Collaboration, Decision) through a
multi-agents collaboration framework. We demonstrate why planning decisions
require explicit reasoning capabilities that are value-based (applying
normative principles), rule-grounded (guaranteeing constraint satisfaction),
and explainable (generating transparent justifications) -- requirements that
statistical learning alone cannot fulfill. We compare reasoning agents with
statistical learning, present a comprehensive architecture with benchmark
evaluation metrics, and outline critical research challenges. This framework
shows how AI agents can augment human planners by systematically exploring
solution spaces, verifying regulatory compliance, and deliberating over
trade-offs transparently -- not replacing human judgment but amplifying it with
computational reasoning capabilities.

</details>
